name: Benchmarks

on:
  workflow_dispatch:
    inputs:
      benchmark_filter:
        description: 'Benchmark filter (e.g., *Serialization*, *Producer*)'
        required: false
        default: '*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  benchmarks:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60
    # Note: Kafka service is managed by Testcontainers in the benchmark code

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
          dotnet-quality: 'preview'

      - name: Restore dependencies
        run: dotnet restore

      - name: Build solution
        run: dotnet build --configuration Release --no-restore

      - name: Run Serialization Benchmarks (No Docker Required)
        id: serialization_benchmarks
        run: |
          cd tools/Dekaf.Benchmarks
          dotnet run -c Release -- --filter "*Serialization*" --exporters json --artifacts ./BenchmarkResults/Serialization
        continue-on-error: true

      - name: Run Memory Benchmarks (No Docker Required)
        id: memory_benchmarks
        run: |
          cd tools/Dekaf.Benchmarks
          dotnet run -c Release -- --filter "*Memory*" --exporters json --artifacts ./BenchmarkResults/Memory
        continue-on-error: true

      - name: Start Kafka
        run: |
          docker run -d --name kafka \
            -p 9092:9092 \
            apache/kafka:latest

          echo "Waiting for Kafka to start..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list 2>/dev/null; then
              echo "Kafka is ready"
              break
            fi
            echo "Attempt $i: Kafka not ready yet..."
            sleep 2
          done

      - name: Run Producer Benchmarks
        id: producer_benchmarks
        env:
          KAFKA_BOOTSTRAP_SERVERS: localhost:9092
        run: |
          cd tools/Dekaf.Benchmarks
          dotnet run -c Release -- --filter "*Producer*" --exporters json --artifacts ./BenchmarkResults/Producer
        continue-on-error: true

      - name: Run Consumer Benchmarks
        id: consumer_benchmarks
        env:
          KAFKA_BOOTSTRAP_SERVERS: localhost:9092
        run: |
          cd tools/Dekaf.Benchmarks
          dotnet run -c Release -- --filter "*Consumer*" --exporters json --artifacts ./BenchmarkResults/Consumer
        continue-on-error: true

      - name: Stop Kafka
        if: always()
        run: docker rm -f kafka || true

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: tools/Dekaf.Benchmarks/BenchmarkResults/
          retention-days: 30

      - name: Generate Benchmark Summary
        run: |
          echo "# Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Run Information" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ubuntu-latest" >> $GITHUB_STEP_SUMMARY
          echo "- **.NET Version:** ${{ env.DOTNET_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check for serialization results
          if [ -d "tools/Dekaf.Benchmarks/BenchmarkResults/Serialization" ]; then
            echo "## Serialization Benchmarks" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Benchmark | Mean | Error | StdDev | Allocated |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|------|-------|--------|-----------|" >> $GITHUB_STEP_SUMMARY

            # Parse JSON results if available
            for f in tools/Dekaf.Benchmarks/BenchmarkResults/Serialization/results/*.json; do
              if [ -f "$f" ]; then
                cat "$f" | jq -r '.Benchmarks[]? | "| \(.Method) | \(.Statistics.Mean | . / 1000000 | . * 100 | round / 100) ms | \(.Statistics.Error | . / 1000000 | . * 100 | round / 100) ms | \(.Statistics.StdDev | . / 1000000 | . * 100 | round / 100) ms | \(.Memory.BytesAllocatedPerOperation // 0) B |"' 2>/dev/null >> $GITHUB_STEP_SUMMARY || true
              fi
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Check for memory results
          if [ -d "tools/Dekaf.Benchmarks/BenchmarkResults/Memory" ]; then
            echo "## Memory Benchmarks" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Benchmark | Mean | Allocated |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|------|-----------|" >> $GITHUB_STEP_SUMMARY

            for f in tools/Dekaf.Benchmarks/BenchmarkResults/Memory/results/*.json; do
              if [ -f "$f" ]; then
                cat "$f" | jq -r '.Benchmarks[]? | "| \(.Method) | \(.Statistics.Mean | . / 1000000 | . * 100 | round / 100) ms | \(.Memory.BytesAllocatedPerOperation // 0) B |"' 2>/dev/null >> $GITHUB_STEP_SUMMARY || true
              fi
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Check for producer results
          if [ -d "tools/Dekaf.Benchmarks/BenchmarkResults/Producer" ]; then
            echo "## Producer Benchmarks (Dekaf vs Confluent.Kafka)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Benchmark | Mean | Error | Allocated |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|------|-------|-----------|" >> $GITHUB_STEP_SUMMARY

            for f in tools/Dekaf.Benchmarks/BenchmarkResults/Producer/results/*.json; do
              if [ -f "$f" ]; then
                cat "$f" | jq -r '.Benchmarks[]? | "| \(.Method) | \(.Statistics.Mean | . / 1000000 | . * 100 | round / 100) ms | \(.Statistics.Error | . / 1000000 | . * 100 | round / 100) ms | \(.Memory.BytesAllocatedPerOperation // 0) B |"' 2>/dev/null >> $GITHUB_STEP_SUMMARY || true
              fi
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Check for consumer results
          if [ -d "tools/Dekaf.Benchmarks/BenchmarkResults/Consumer" ]; then
            echo "## Consumer Benchmarks (Dekaf vs Confluent.Kafka)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Benchmark | Mean | Error | Allocated |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|------|-------|-----------|" >> $GITHUB_STEP_SUMMARY

            for f in tools/Dekaf.Benchmarks/BenchmarkResults/Consumer/results/*.json; do
              if [ -f "$f" ]; then
                cat "$f" | jq -r '.Benchmarks[]? | "| \(.Method) | \(.Statistics.Mean | . / 1000000 | . * 100 | round / 100) ms | \(.Statistics.Error | . / 1000000 | . * 100 | round / 100) ms | \(.Memory.BytesAllocatedPerOperation // 0) B |"' 2>/dev/null >> $GITHUB_STEP_SUMMARY || true
              fi
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          echo "## Notes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Producer and Consumer benchmarks run against Kafka in Docker (apache/kafka)" >> $GITHUB_STEP_SUMMARY
          echo "- Memory benchmarks highlight Dekaf's zero-allocation design" >> $GITHUB_STEP_SUMMARY
          echo "- Full results are available in the uploaded artifacts" >> $GITHUB_STEP_SUMMARY

  benchmark-comparison:
    name: Store Benchmark History
    runs-on: ubuntu-latest
    needs: benchmarks
    if: github.ref == 'refs/heads/main'

    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Benchmark Results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results

      - name: Store Benchmark Results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Dekaf Benchmarks
          tool: 'benchmarkdotnet'
          output-file-path: benchmark-results/**/*.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
          alert-comment-cc-users: '@thomholloway'
